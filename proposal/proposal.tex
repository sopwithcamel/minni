%! program = pdflatex

%\documentclass[12pt,a4paper]{memoir} % for a long document
\documentclass[10pt,letter,final,article,twocolumn]{article} % for a short document
\usepackage[left=0.25in,top=0.25in,right=0.25in,bottom=0.25in,nohead,nofoot]{geometry} 
\usepackage{titling,url}
% See the ``Memoir customise'' template for some common customisations
% Don't forget to read the Memoir manual: memman.pdf

\title{LWMR: Lightweight MapReduce}
\author{Athula Balachandran \\
{\tt abalacha@cs.cmu.edu}
\and
Wolfgang Richter \\
{\tt wolf@cs.cmu.edu}
\and
Erik Zawadzki \\
{\tt epz@cs.cmu.edu}}
\date{February 12, 2010} % delete this line to display the current date

%%% BEGIN DOCUMENT
\begin{document}

\pagestyle{empty}
\maketitle
\thispagestyle{empty}

\section{Problem Definition}
MapReduce~\cite{mapreduce08} is a framework that allows programmers to easily write applications that process large data-sets in a reliable and fault-tolerant manner on large clusters involving commodity hardware. The basic implementation  comprises of two stages---map and reduce. The input data set is split into independent chunks and are parallely processed by the map tasks. The output from this stage is then passed (sometimes after an intermediate local sorting stage called combine) to the reduce tasks. The framework abstracts all details like scheduling tasks, monitoring them and re-execution of failed tasks. 

The architecture typically conisists of a master node and several worker nodes that store data as well as do map/reduce jobs assigned by the master. The fact that the worker nodes store data as well as process them has been used to come up with efficient scheduling techniques that take into account locality and minimization of network traffic.

Most of the already existing implementations of MapReduce try to minimize communication overhead between the worker machines. However memory footprint is not of important consideration in many design decisions. This is of importantance while designing MapReduce for systems like FAWN~\cite{fawn09}. In this project, we try to identify design possibilities that are key to decreasing memory footprint and we plan to reimplement a light weight MapReduce architecture that can be potentially be used by systems like FAWN.

\section{Previous Work}

As a foundation, we are designing our implementation based on the original 
description of MapReduce~\cite{mapreduce08}.  Other systems such as
Dryad~\cite{dryad07} provide design considerations and expose areas
where we can innovate with our implementation.  Our implementation on top
of FAWN~\cite{fawn09} introduces a particular constraint that the original
MapReduce design did not consider: low memory.  In addition, FAWN uses
flash storage as its principal storage medium which introduces another
area for MapReduce research---the original MapReduce design assumes a
storage medium of hard drives.  

Several other competing MapReduce implementations, such as
Disco~\cite{disco10}, Hadoop~\cite{hadoop10}, Sector and
Sphere~\cite{sphere09}, offer more examples to draw from for design
decisions.  Research has also shown that techniques such as merging the
MapReduce stages~\cite{barrier10}, and dynamically prioritizing resource
usage~\cite{sandholm09} offer substantial performance benefits over the
standard MapReduce design---techniques which have only been simulated
before.  Finally, we can take advantage of FAWN's energy efficiency which is
an active area of research with MapReduce as reflected in
Gordon~\cite{gordon09},  and work analyzing MapReduce traces for future
energy efficiency goals~\cite{chen10}.

\section{Architecture}

\section{Design Plan (?)}

\section{Milestone Deliverables}
We plan to prototype the architecture in C++ using the Apache Thrift framework for implementing RPCs. We will use the prototype to test and study how different design decisions affect the performance of MapReduce. After identifying them we will fine tune our final implementation for optimal memory, power, and network usage.


\bibliographystyle{plain}
\bibliography{references}


\end{document}
